pre_1900s %>% filter(Date > 1971-04-01)
## filter in pre 1900s until date that seventies pre doesnt exist
pre_1900s %>% filter(Date < 1971-04-01)
## filter in pre 1900s until date that seventies pre doesnt exist
pre_1900s %>% filter(Date < 1971-04-01)	%>% View()
## filter in pre 1900s until date that seventies pre doesnt exist
pre_1900s %>% filter(Date <= 1971-04-01)
## filter in pre 1900s until date that seventies pre doesnt exist
pre_1900s %>% filter(Date >= 1971-04-01)
## filter in pre 1900s until date that seventies pre doesnt exist
pre_1900s %>% filter(Date <= 1971-04-01)
## filter in pre 1900s until date that seventies pre doesnt exist
pre_1900s %>% filter(Date <= as.Date("1971-04-01"))
## filter in pre 1900s until date that seventies pre doesnt exist
pre_1900s %>% filter(Date <= as.Date("1971-04-01"))	%>% View()
## filter in pre 1900s until date that seventies pre doesnt exist
pre_1900s %>% filter(Date < as.Date("1971-04-01"))	%>% View()
## filter in pre 1900s until date that seventies pre doesnt exist
pre_1900s<- pre_1900s %>% filter(Date < as.Date("1971-04-01"))
# Clean environment ####
rm(list = ls())
#### BCI precip data --------
seventies_rain <- read_csv("C:/Users/GonzalezB2/Desktop/Smithsonian/Climate/Climate_Data/Met_Stations/BCI/El_Claro_precip_starting_1929/20180168_bci_manual_cl_ra/bci_cl_ra_man.csv")
rain_1900s <- read_csv("C:/Users/GonzalezB2/Desktop/Smithsonian/Climate/Climate_Data/Met_Stations/BCI/El_Claro_precip_starting_1929/20180168_bci_manual_cl_ra/rain_acp_ra_1929_1971.csv")
## Change names, format dates for 1900s and 1970s data
rain_1900s<- rain_1900s %>% rename(Date =`Date(yyyy-mm-dd)`)
rain_1900s$Date <- as.Date(rain_1900s$Date, "%d/%m/%Y")
seventies_rain<- seventies_rain %>% rename(Date =date, avg_rain=ra)
seventies_rain$Date <- as.Date(seventies_rain$Date, "%d/%m/%Y")
## filter in pre 1900s until date that seventies pre doesnt exist
pre_1900s<- pre_1900s %>% filter(Date < as.Date("1971-04-01"))
## FOR PRE FORMATTING ----
seventies_PRE <- seventies_rain %>% group_by(Date=floor_date(Date, "month")) %>% summarize(climvar.val=sum(avg_rain))
pre_1900s <- rain_1900s %>% group_by(Date=floor_date(Date, "month")) %>% summarize(climvar.val=sum(`rain (mm)`))
# bind these puppies, add relevent cols, and write.csv
pre_BCI <- rbind(pre_1900s, seventies_PRE)
pre_BCI$sites.sitename <- rep("Barro Colorado Island", nrow(pre_BCI))
pre_BCI$month<- month(pre_BCI$Date)
pre_BCI$climvar.class <- rep("pre", nrow(pre_BCI))
# rearrange cols to match long format
pre_BCI<- pre_BCI[c(3,1,2,5,4)]
View(pre_BCI)
# Clean environment ####
rm(list = ls())
#### BCI precip data --------
seventies_rain <- read_csv("C:/Users/GonzalezB2/Desktop/Smithsonian/Climate/Climate_Data/Met_Stations/BCI/El_Claro_precip_starting_1929/20180168_bci_manual_cl_ra/bci_cl_ra_man.csv")
rain_1900s <- read_csv("C:/Users/GonzalezB2/Desktop/Smithsonian/Climate/Climate_Data/Met_Stations/BCI/El_Claro_precip_starting_1929/20180168_bci_manual_cl_ra/rain_acp_ra_1929_1971.csv")
View(seventies_rain)
## Change names, format dates for 1900s and 1970s data
rain_1900s<- rain_1900s %>% rename(Date =`Date(yyyy-mm-dd)`)
rain_1900s$Date <- as.Date(rain_1900s$Date, "%d/%m/%Y")
seventies_rain<- seventies_rain %>% rename(Date =date, avg_rain=ra)
seventies_rain$Date <- as.Date(seventies_rain$Date, "%d/%m/%Y")
## FOR PRE FORMATTING ----
seventies_PRE <- seventies_rain %>% group_by(Date=floor_date(Date, "month")) %>% summarize(climvar.val=sum(avg_rain))
pre_1900s <- rain_1900s %>% group_by(Date=floor_date(Date, "month")) %>% summarize(climvar.val=sum(`rain (mm)`))
View(seventies_PRE)
View(pre_1900s)
View(seventies_PRE)
## filter in pre 1900s until date that seventies pre doesnt exist
pre_1900s<- pre_1900s %>% filter(Date < as.Date("1971-04-01"))
# bind these puppies, add relevent cols, and write.csv
pre_BCI <- rbind(pre_1900s, seventies_PRE)
View(pre_BCI)
pre_BCI$sites.sitename <- rep("Barro Colorado Island", nrow(pre_BCI))
pre_BCI$month<- month(pre_BCI$Date)
pre_BCI$climvar.class <- rep("pre", nrow(pre_BCI))
View(pre_BCI)
# rearrange cols to match long format
pre_BCI<- pre_BCI[c(3,1,2,5,4)]
View(pre_BCI)
pre_BCI
# fill in missing dates
pre_BCI %>% pad(interval = month)
# fill in missing dates
pad(pre_BCI, interval = month)
# fill in missing dates
pad(pre_BCI, interval = "month")
pre_BCI
pre_BCI %>% complete(Date = seq.Date(min(Date), max(Date), by="month"))
install.pcakages(tidyr)
install.packages(tidyr)
install.packages("tidyr")
install.packages("tidyr")
library(tidyr)
pre_BCI %>% complete(Date = seq.Date(min(Date), max(Date), by="month"))
pre_BCI
View(pre_BCI)
## write.csv for PRE
write.csv(pre_BCI, paste0(getwd(), "/Climate_Data/Met_Stations/BCI/pre_BCI.csv"), row.names = F)
wet_1900s<- rain_1900s %>% group_by(Date=floor_date(Date, "month")) %>% filter(`rain (mm)`>.1) %>% tally()
library(dplyr)
wet_1900s<- rain_1900s %>% group_by(Date=floor_date(Date, "month")) %>% filter(`rain (mm)`>.1) %>% tally()
wet_1900s<- rain_1900s %>% group_by(Date=floor_date(Date, "month")) %>% filter(`rain (mm)`>.1) %>% tally()
library(lubridate)
wet_1900s<- rain_1900s %>% group_by(Date=floor_date(Date, "month")) %>% filter(`rain (mm)`>.1) %>% tally()
wet_1970s<- seventies_rain %>% group_by(Date=floor_date(Date, "month")) %>% filter(avg_rain>.1) %>% tally()
# bind these puppies, add relevent cols, and write.csv
wet_BCI <- rbind(wet_1900s, wet_1970s)
wet_BCI$sites.sitename <- rep("Barro Colorado Island", nrow(wet_BCI))
wet_BCI$month<- month(wet_BCI$Date)
wet_BCI$climvar.class <- rep("wet", nrow(wet_BCI))
wet_BCI<- wet_BCI %>% rename(climvar.val= n)
# rearrange cols to match long format
wet_BCI<- wet_BCI[c(3,1,2,5,4)]
View(wet_1900s)
## filter in pre 1900s until date that seventies pre doesnt exist
wet_1900s<- wet_1900s %>% filter(Date < as.Date("1971-04-01"))
wet_1900s<- rain_1900s %>% group_by(Date=floor_date(Date, "month")) %>% filter(`rain (mm)`>.1) %>% tally()
wet_1970s<- seventies_rain %>% group_by(Date=floor_date(Date, "month")) %>% filter(avg_rain>.1) %>% tally()
## filter in pre 1900s until date that seventies pre doesnt exist
wet_1900s<- wet_1900s %>% filter(Date < as.Date("1971-04-01"))
# bind these puppies, add relevent cols, and write.csv
wet_BCI <- rbind(wet_1900s, wet_1970s)
wet_BCI$sites.sitename <- rep("Barro Colorado Island", nrow(wet_BCI))
wet_BCI$month<- month(wet_BCI$Date)
wet_BCI$climvar.class <- rep("wet", nrow(wet_BCI))
wet_BCI<- wet_BCI %>% rename(climvar.val= n)
# rearrange cols to match long format
wet_BCI<- wet_BCI[c(3,1,2,5,4)]
View(wet_BCI)
## write.csv for PRE
write.csv(wet_BCI, paste0(getwd(), "/Climate_Data/Met_Stations/BCI/wet_BCI.csv"), row.names = F)
## write.csv for PRE
write.csv(pre_BCI, paste0(getwd(), "/Climate_Data/Met_Stations/BCI/El_Claro_precip_starting_1929/pre_BCI.csv"), row.names = F)
## write.csv for PRE
write.csv(wet_BCI, paste0(getwd(), "/Climate_Data/Met_Stations/BCI/El_Claro_precip_starting_1929/wet_BCI.csv"), row.names = F)
##########
library(readr)
library(ggplot2)
library(plotly)
library(anytime)
library(dplyr)
library(viridis)
# Clean environment ####
rm(list = ls())
#### Sites --------
# ForestGeo sites (and their locations) found in github (all 69)
ForestGEO_sites <- read.csv("https://raw.githubusercontent.com/forestgeo/Site-Data/master/ForestGEO_site_data.csv")
# See comments @ end of code for site indices
fsites<-c("Smithsonian Environmental Research Center","Harvard Forest"
,"Smithsonian Conservation Biology Institute", "Lilly Dickey Woods"
,"Ordway-Swisher"                             ,"Yosemite National Park"
,"Wind River"                                 ,"Utah Forest Dynamics Plot"
,"Huai Kha Khaeng"                            ,"Barro Colorado Island",
"Zofin", "Scotty Creek")
# Sites in climate data have _ so replace space with _ to match later
fsites<- gsub(" ", "_", fsites)
path_to_climate_data <- "https://raw.githubusercontent.com/forestgeo/Climate/master/Climate_Data/CRU/CRU_v4_04/"
v<- c("cld", "dtr", "frs", "pet", "pre", "tmn", "tmp", "tmn", "tmx", "vap", "wet")
objs<- vector(mode = "list", length = length(v))
counter <- 0
for(clim_v in v) { #  clim_v is each climate variable (v)
counter<- counter + 1
print(paste0(clim_v, " ", counter))
objs[[counter]]<-read.csv(paste0(path_to_climate_data, clim_v, ".1901.2019-ForestGEO_sites-6-03.csv"))
names(objs)[counter] <- clim_v # assign names to list
# adding a col that will show the climate variable (ie cld or pet)
objs[[counter]]$clim<-  gsub(names(objs[counter]), v[counter], names(objs[counter]), ignore.case = FALSE)
}
# CRU data with final sites and storage vessel list for the long format of data
CRU_fsites <- vector(mode="list", length=length(fsites)*length(v)) # I should have ten of each site (so fsites*v)
storage.vess<- vector(mode="list", length=length(fsites)*length(v)) # and I should have a storage vessel with just as manny
counter=0
View(objs)
objs[[1]]
objs[[1]] %>% View()
for(j in fsites){ # 110 times because 11 clim vars and 10 sites
for(i in seq_along(v)){
# i is seq # 1-11 of climvar objs ----- j is fsite raw - smithsonian ---- counter is the iterative # ie 110
# for each climvar in objs we should have a smithsonian for cld smithsonian for dtr etc et
#### Select only FSITES from climvar data
counter <- counter +1 # running fsites* clim vars
print(paste0(j," counter # ", counter, " and clim var ", names(objs[i])))
CRU_fsites[[counter]] <- objs[[i]][match(j, objs[[i]]$sites.sitename),] #go through each climvar and find the specified J aka site
#### Transform data to long format
df<- as.data.frame(CRU_fsites[[counter]]) # make df object
df_long<- reshape(df, #reshape data for plot
times =gsub("X", "", names(df)[-1]),
timevar = "Date",
varying = list(colnames(df[-1])),
v.names = paste0(df$clim),
direction = "long",)
storage.vess[[counter]]<- df_long # store newly reshaped data in new storage vessel
names(storage.vess)[counter] <- j
# clean up data: date formats, climvar column, ordering the vector for later analysis.
storage.vess[[counter]]$Date<- anytime::anydate(storage.vess[[counter]]$Date) # change to Date format
storage.vess[[counter]]$climvar <- rep(names(storage.vess[[counter]])[3], times=nrow(storage.vess[[counter]])) # add the climvar column here (needs to be index)
storage.vess[[counter]][,"month"] <- format(storage.vess[[counter]][,"Date"], "%m") # add month col for later processing! --
storage.vess[[counter]]<-storage.vess[[counter]][order(as.numeric(storage.vess[[counter]]$month)),] # order the columns by month so we can use the RLE function
storage.vess[[counter]]<- storage.vess[[counter]] %>%
rename(climvar.class =climvar,
climvar.val = names(storage.vess[[counter]][3]))
# ## We'll want to exclude frs=0
storage.vess[[counter]]<-storage.vess[[counter]] %>% filter(climvar.class != "frs" & climvar.val !=0)
storage.vess[[counter]]$month <-as.integer(storage.vess[[counter]]$month) # make months ints for later analysis
}
}
storage.vess[[125]]
storage.vess[[125]] %>% View()
storage.vess[[125]]
## scotty Creek is missing some values so fill them in
pad(storage.vess[[125]], interval = "month")
library(padr)
## scotty Creek is missing some values so fill them in
pad(storage.vess[[125]], interval = "month")
class(storage.vess[[125]]$Date)
storage.vess[[125]] %>% View()
climate_variables <- c( "pre", "wet",
"tmp", "tmn", "tmx", "pet",
"dtr", "cld") # "frs", "vap"
## climate data ####
for(clim_v in climate_variables) {
print(clim_v)
x <- get(clim_v)
### subset for the sites we care about
x <- x[x$sites.sitename %in% sites.sitenames, ]
### reshape to long format
x_long <- reshape(x,
times = names(x)[-1], timevar = "Date",
varying = list(names(x)[-1]), direction = "long", v.names = clim_v)
### format date
x_long$Date <- gsub("X", "", x_long$Date)
x_long$Date <- as.Date(x_long$Date , format = "%Y.%m.%d")
### combine all variables in one
if(clim_v == climate_variables [1]) all_Clim <- x_long[, c(1:3)]
else all_Clim <- merge(all_Clim, x_long[, c(1:3)], by = c("sites.sitename", "Date"), all = T)
}
x <- get(clim_v)
clim_v
get(clim_v)
climate_variables <- c( "pre", "wet",
"tmp", "tmn", "tmx", "pet",
"dtr", "cld") # "frs", "vap"
for(clim_v in climate_variables) {
assign(clim_v,
rbind(
read.csv(paste0(path_to_climate_data, clim_v,  ".1901.2019-ForestGEO_sites-6-03.csv")), #forestGEO sites
read.csv(paste0(path_to_climate_data_NM, clim_v, ".1901.2019-NM_site-7-10.csv")) # NM site
)
)
}
path_to_climate_data <- "https://raw.githubusercontent.com/forestgeo/Climate/master/Climate_Data/CRU/CRU_v4_04/" # "https://raw.githubusercontent.com/forestgeo/Climate/master/Gridded_Data_Products/Historical%20Climate%20Data/CRU_v4_01/" #
path_to_climate_data_NM <- "C:/Users/HerrmannV/Dropbox (Smithsonian)/GitHub/EcoClimLab/ForestGEO_dendro/data/cores/NM/CRU_climate/" # *TO BE EDITED* because the dendro repo is private... I ave to give absolute path (tokens are changing all the time in Github with private repos.... so it would be a pain to have to change them everytime...)
for(clim_v in climate_variables) {
assign(clim_v,
rbind(
read.csv(paste0(path_to_climate_data, clim_v,  ".1901.2019-ForestGEO_sites-6-03.csv")), #forestGEO sites
read.csv(paste0(path_to_climate_data_NM, clim_v, ".1901.2019-NM_site-7-10.csv")) # NM site
)
)
}
path_to_climate_data <- "https://raw.githubusercontent.com/forestgeo/Climate/master/Climate_Data/CRU/CRU_v4_04/" # "https://raw.githubusercontent.com/forestgeo/Climate/master/Gridded_Data_Products/Historical%20Climate%20Data/CRU_v4_01/" #
for(clim_v in climate_variables) {
assign(clim_v,
rbind(
read.csv(paste0(path_to_climate_data, clim_v,  ".1901.2019-ForestGEO_sites-6-03.csv")), #forestGEO sites
#  read.csv(paste0(path_to_climate_data_NM, clim_v, ".1901.2019-NM_site-7-10.csv")) # NM site
)
)
}
for(clim_v in climate_variables) {
assign(clim_v,
# rbind(
read.csv(paste0(path_to_climate_data, clim_v,  ".1901.2019-ForestGEO_sites-6-03.csv")) #forestGEO sites
#  read.csv(paste0(path_to_climate_data_NM, clim_v, ".1901.2019-NM_site-7-10.csv")) # NM site
# )
)
}
## climate data ####
for(clim_v in climate_variables) {
print(clim_v)
x <- get(clim_v)
### subset for the sites we care about
x <- x[x$sites.sitename %in% sites.sitenames, ]
### reshape to long format
x_long <- reshape(x,
times = names(x)[-1], timevar = "Date",
varying = list(names(x)[-1]), direction = "long", v.names = clim_v)
### format date
x_long$Date <- gsub("X", "", x_long$Date)
x_long$Date <- as.Date(x_long$Date , format = "%Y.%m.%d")
### combine all variables in one
if(clim_v == climate_variables [1]) all_Clim <- x_long[, c(1:3)]
else all_Clim <- merge(all_Clim, x_long[, c(1:3)], by = c("sites.sitename", "Date"), all = T)
}
sites.sitenames <- c(BCI = "Barro_Colorado_Island",
CedarBreaks = "Utah_Forest_Dynamics_Plot",
HarvardForest = "Harvard_Forest",
LillyDickey = "Lilly_Dickey_Woods",
SCBI = "Smithsonian_Conservation_Biology_Institute",
ScottyCreek = "Scotty_Creek",
Zofin = "Zofin",
HKK = "Huai_Kha_Khaeng")#,
## climate data ####
for(clim_v in climate_variables) {
print(clim_v)
x <- get(clim_v)
### subset for the sites we care about
x <- x[x$sites.sitename %in% sites.sitenames, ]
### reshape to long format
x_long <- reshape(x,
times = names(x)[-1], timevar = "Date",
varying = list(names(x)[-1]), direction = "long", v.names = clim_v)
### format date
x_long$Date <- gsub("X", "", x_long$Date)
x_long$Date <- as.Date(x_long$Date , format = "%Y.%m.%d")
### combine all variables in one
if(clim_v == climate_variables [1]) all_Clim <- x_long[, c(1:3)]
else all_Clim <- merge(all_Clim, x_long[, c(1:3)], by = c("sites.sitename", "Date"), all = T)
}
View(x_long)
View(all_Clim)
clim_v
?get()
x[x$sites.sitename %in% sites.sitenames, ]
### reshape to long format
x_long <- reshape(x,
times = names(x)[-1], timevar = "Date",
varying = list(names(x)[-1]), direction = "long", v.names = clim_v)
x_long
climate_variables [1]
x_long[, c(1:3)]
# CRU data with final sites and storage vessel list for the long format of data
CRU_fsites <- vector(mode="list", length=length(fsites)*length(v)) # I should have ten of each site (so fsites*v)
storage.vess<- vector(mode="list", length=length(fsites)*length(v)) # and I should have a storage vessel with just as manny
counter=0
for(j in fsites){ # 110 times because 11 clim vars and 10 sites
for(i in seq_along(v)){
# i is seq # 1-11 of climvar objs ----- j is fsite raw - smithsonian ---- counter is the iterative # ie 110
# for each climvar in objs we should have a smithsonian for cld smithsonian for dtr etc et
#### Select only FSITES from climvar data
counter <- counter +1 # running fsites* clim vars
print(paste0(j," counter # ", counter, " and clim var ", names(objs[i])))
CRU_fsites[[counter]] <- objs[[i]][match(j, objs[[i]]$sites.sitename),] #go through each climvar and find the specified J aka site
#### Transform data to long format
df<- as.data.frame(CRU_fsites[[counter]]) # make df object
df_long<- reshape(df, #reshape data for plot
times =gsub("X", "", names(df)[-1]),
timevar = "Date",
varying = list(colnames(df[-1])),
v.names = paste0(df$clim),
direction = "long",)
storage.vess[[counter]]<- df_long # store newly reshaped data in new storage vessel
names(storage.vess)[counter] <- j
# clean up data: date formats, climvar column, ordering the vector for later analysis.
storage.vess[[counter]]$Date<- anytime::anydate(storage.vess[[counter]]$Date) # change to Date format
storage.vess[[counter]]$climvar <- rep(names(storage.vess[[counter]])[3], times=nrow(storage.vess[[counter]])) # add the climvar column here (needs to be index)
storage.vess[[counter]][,"month"] <- format(storage.vess[[counter]][,"Date"], "%m") # add month col for later processing! --
storage.vess[[counter]]<-storage.vess[[counter]][order(as.numeric(storage.vess[[counter]]$month)),] # order the columns by month so we can use the RLE function
storage.vess[[counter]]<- storage.vess[[counter]] %>%
rename(climvar.class =climvar,
climvar.val = names(storage.vess[[counter]][3]))
# ## We'll want to exclude frs=0
storage.vess[[counter]]<-storage.vess[[counter]] %>% filter(climvar.class != "frs")
storage.vess[[counter]]$month <-as.integer(storage.vess[[counter]]$month) # make months ints for later analysis
}
}
storage.vess[[125]]
storage.vess[[125]] %>% View()
##########
library(readr)
library(ggplot2)
library(plotly)
library(anytime)
library(dplyr)
library(padr)
library(viridis)
# Clean environment ####
rm(list = ls())
#### Sites --------
# ForestGeo sites (and their locations) found in github (all 69)
ForestGEO_sites <- read.csv("https://raw.githubusercontent.com/forestgeo/Site-Data/master/ForestGEO_site_data.csv")
# See comments @ end of code for site indices
fsites<-c("Smithsonian Environmental Research Center","Harvard Forest"
,"Smithsonian Conservation Biology Institute", "Lilly Dickey Woods"
,"Ordway-Swisher"                             ,"Yosemite National Park"
,"Wind River"                                 ,"Utah Forest Dynamics Plot"
,"Huai Kha Khaeng"                            ,"Barro Colorado Island",
"Zofin", "Scotty Creek")
# Sites in climate data have _ so replace space with _ to match later
fsites<- gsub(" ", "_", fsites)
path_to_climate_data <- "https://raw.githubusercontent.com/forestgeo/Climate/master/Climate_Data/CRU/CRU_v4_04/"
v<- c("cld", "dtr", "frs", "pet", "pre", "tmn", "tmp", "tmn", "tmx", "vap", "wet")
# Clean environment ####
rm(list = ls())
#### Sites --------
# ForestGeo sites (and their locations) found in github (all 69)
ForestGEO_sites <- read.csv("https://raw.githubusercontent.com/forestgeo/Site-Data/master/ForestGEO_site_data.csv")
# See comments @ end of code for site indices
fsites<-c("Smithsonian Environmental Research Center","Harvard Forest"
,"Smithsonian Conservation Biology Institute", "Lilly Dickey Woods"
,"Ordway-Swisher"                             ,"Yosemite National Park"
,"Wind River"                                 ,"Utah Forest Dynamics Plot"
,"Huai Kha Khaeng"                            ,"Barro Colorado Island",
"Zofin", "Scotty Creek")
# Sites in climate data have _ so replace space with _ to match later
fsites<- gsub(" ", "_", fsites)
path_to_climate_data <- "https://raw.githubusercontent.com/forestgeo/Climate/master/Climate_Data/CRU/CRU_v4_04/"
v<- c("cld", "dtr", "frs", "pet", "pre", "tmn", "tmp", "tmn", "tmx", "vap", "wet")
objs<- vector(mode = "list", length = length(v))
counter <- 0
for(clim_v in v) { #  clim_v is each climate variable (v)
counter<- counter + 1
print(paste0(clim_v, " ", counter))
objs[[counter]]<-read.csv(paste0(path_to_climate_data, clim_v, ".1901.2019-ForestGEO_sites-6-03.csv"))
names(objs)[counter] <- clim_v # assign names to list
# adding a col that will show the climate variable (ie cld or pet)
objs[[counter]]$clim<-  gsub(names(objs[counter]), v[counter], names(objs[counter]), ignore.case = FALSE)
}
# CRU data with final sites and storage vessel list for the long format of data
CRU_fsites <- vector(mode="list", length=length(fsites)*length(v)) # I should have ten of each site (so fsites*v)
# CRU data with final sites and storage vessel list for the long format of data
CRU_fsites <- vector(mode="list", length=length(fsites)*length(v)) # I should have ten of each site (so fsites*v)
storage.vess<- vector(mode="list", length=length(fsites)*length(v)) # and I should have a storage vessel with just as manny
counter=0
for(j in fsites){ # 110 times because 11 clim vars and 10 sites
for(i in seq_along(v)){
# i is seq # 1-11 of climvar objs ----- j is fsite raw - smithsonian ---- counter is the iterative # ie 110
# for each climvar in objs we should have a smithsonian for cld smithsonian for dtr etc et
#### Select only FSITES from climvar data
counter <- counter +1 # running fsites* clim vars
print(paste0(j," counter # ", counter, " and clim var ", names(objs[i])))
CRU_fsites[[counter]] <- objs[[i]][match(j, objs[[i]]$sites.sitename),] #go through each climvar and find the specified J aka site
#### Transform data to long format
df<- as.data.frame(CRU_fsites[[counter]]) # make df object
df_long<- reshape(df, #reshape data for plot
times =gsub("X", "", names(df)[-1]),
timevar = "Date",
varying = list(colnames(df[-1])),
v.names = paste0(df$clim),
direction = "long",)
storage.vess[[counter]]<- df_long # store newly reshaped data in new storage vessel
names(storage.vess)[counter] <- j
# clean up data: date formats, climvar column, ordering the vector for later analysis.
storage.vess[[counter]]$Date<- anytime::anydate(storage.vess[[counter]]$Date) # change to Date format
storage.vess[[counter]]$climvar <- rep(names(storage.vess[[counter]])[3], times=nrow(storage.vess[[counter]])) # add the climvar column here (needs to be index)
storage.vess[[counter]][,"month"] <- format(storage.vess[[counter]][,"Date"], "%m") # add month col for later processing! --
storage.vess[[counter]]<-storage.vess[[counter]][order(as.numeric(storage.vess[[counter]]$month)),] # order the columns by month so we can use the RLE function
storage.vess[[counter]]<- storage.vess[[counter]] %>%
rename(climvar.class =climvar,
climvar.val = names(storage.vess[[counter]][3]))
# ## We'll want to exclude frs=0
storage.vess[[counter]]<-storage.vess[[counter]] %>% filter(climvar.class != "frs")
storage.vess[[counter]]$month <-as.integer(storage.vess[[counter]]$month) # make months ints for later analysis
}
}
### now for the length of storage vess: 12 different month and dfs combos --
months_list<- vector(mode="list", length=length(storage.vess)*12) # one for each month
counter = 0
for(m in 1:12){
for(i in 1:length(storage.vess)){  # so 12 months per cld # 12 * 11 (sites - climvar - month combos)
## first 11 (climvars) are dfs of each location with climvar -- 12 month combos per df
## 12 months and 166 dataframes with climvar data per sites so 12 * # of dfs
counter = counter+1
print(paste0("month ", m, " i ", i, " counter for dataframes from storage vess (made of 11 diff climvars and each site) ", counter))
months_list[[counter]]<- storage.vess[[i]] %>%  dplyr::filter(climvar.class ==storage.vess[[i]]$climvar.class[1] & month ==m)
#### REPS MONTH ANALYSIS --------------------
if(nrow(months_list[[counter]]) !=0){ # if the dataframe is empty dont go in here
repsmo<- rle(months_list[[counter]][,3])
end = cumsum(repsmo$lengths)
start = c(1, lag(end)[-1] + 1) # https://stackoverflow.com/questions/43875716/find-start-and-end-positions-indices-of-runs-consecutive-values
start.end.indices <-data.frame(start,end) #lags by one - shifts to the left , -1 puts it back ot original place and +1 adds the number to index (c(1)) - lag maintains length
start.df<-months_list[[counter]][start,] # add colanmes to start and end values
end.df<- months_list[[counter]][end,]
colnames(start.df) <- paste0('start_', colnames(start.df))
colnames(end.df) <- paste0('end_', colnames(end.df))
df.indices<-cbind(start.df,end.df) # bind both dataframes
rownames(df.indices)<-c(1:nrow(df.indices)) #change rownames to sequential order
selection<-cbind(df.indices, start.end.indices) # add start and end indices column
selection$rep.yrs <-selection$end -selection$start # 0 is a 0
selection<- selection %>% filter(selection$rep.yrs>=2) # grab only repitions greater than 2 years
selection$rep.yrs <- selection$rep.yrs+1 # add one to all instances to account for start years
months_list[[counter]]<- selection
# ## arrange for ease of viewing, select only relevent variables
months_list[[counter]]<-months_list[[counter]] %>% arrange(desc(rep.yrs))
months_list[[counter]]<- months_list[[counter]][c('start_sites.sitename', 'start_Date', 'start_climvar.val', 'start_climvar.class', 'start_month', 'end_Date', 'rep.yrs')]
# # ## grab years only for start / end dates
months_list[[counter]]$start_Date<-as.numeric(format(months_list[[counter]]$start_Date,"%Y"))
months_list[[counter]]$end_Date<-as.numeric(format(months_list[[counter]]$end_Date,"%Y"))
# # ## Exclude frs=0
months_list[[counter]]<-months_list[[counter]] %>% filter(start_climvar.class != "frs" & start_climvar.val !=0)
}
}
}
## make DF from list above
sites_reps<-do.call("rbind", months_list)
sites_reps<- sites_reps %>% rename(month = start_month) #rename startmonth to month
#----#----#----#----#----#----#----#----#----#----#----#----#----#----#----#----#----#----#----#----#----#----#----#----
sites_reps$nyears<- sites_reps$end_Date- sites_reps$start_Date+1
problemsites<- sites_reps[sites_reps$nyears != sites_reps$rep.yrs,]
## without the problem sites
sites_reps<- sites_reps[sites_reps$nyears == sites_reps$rep.yrs,]
sites_reps[sites_reps$nyears == sites_reps$rep.yrs,]
problemsites
## add col with number of dates missing
sites_reps$n.missing <- sites_reps$nyears - sites_reps$rep.yrs
sites_reps$n.missing
getwd()
##change wd
setwd(paste0(getwd(), "/Climate_Data/CRU/scripts/CRU_gaps_analysis"))
##write.csv remember to always include row.names = FALSE.
write.csv(sites_reps, "all_sites.reps.csv", row.names = FALSE)
## write csv of problem sites where rep years wont be accurate due to jumps in data
write.csv(problemsites, "problem_sites.csv", row.names=FALSE)
library(readr)
all_sites_reps <- read_csv("all_sites.reps.csv")
View(all_sites_reps)
View(sites_reps)
##write.csv remember to always include row.names = FALSE.
write.csv(sites_reps, "all_sites.reps.csv", row.names = FALSE)
getwd()
