---
title: "CRU Download Instructions"
author: "Original R code by Amy Bennett, updated by Valentine Hermann, Maria Wang, and Bianca Gonzalez"
date: "5/22/2020"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```


## Variables: abbreviations, definitions, units


Label         Variable                    Units
------   ------------------------------   -----------------------------
cld	     cloud cover	                    Percentage (%)
dtr	     diurnal temperature range      	Degrees Celsius
frs	     frost day frequency	            Days
pet	     potential evapotranspiration   	Millimetres per day
pre	     precipitation	                  Millimetres per month
rhm	     relative humidity	              Percentage (%)
ssh      sunshine duration	              Hours
tmp      daily mean temperature	          Degrees Celsius
tmn	     monthly avg daily min temp	      Degrees Celsius
tmx	     monthly avg daily max temp     	Degrees Celsius
vap      vapour pressure	                Hectopascals (hPa)
wet	     wet day frequency	              Days
wnd	     wind                             Speed	metres per second (m/s)
------  -------------------------------   -----------------------------

## Background on Windows
-	Time series data downloaded from http://data.ceda.ac.uk/badc/cru/data/cru_ts/ (you have to register for an account but the data is freely available)
-	CRU TS 4.03 (latest; downloaded by Bianca Gonzalez in May 2020)
-	0.5 x 0.5 degree grids
-	Monthly means from weather stations
-	1901-2018
-	Download easily using FTP transfer using File Explorer (Win 7 and above). Type ftp.ceda.ac.uk in the address bar in Windows Explorer, enter your badc account username and password, navigate to badc/cru/data/cru_ts/[etc.] Then save the .gz files to a folder on your computer. (downloading nc.gz rather than .nc is much faster, but then needs to be decompressed, see below, so it might end up being the same time…). Pick the one file that has the longest span (1901-2016) for each variable.
-	.gz files saved in S:\Global Maps Data\CRU\v4.03
- Create your own version folder in CRU to store most up to date data when using the brick_CRU_BG script  
-	Files must be decompressed from .gz to NetCDF (can be done in R or using 7zip – much faster in R)
-	See updated brick_CRU_BG script to decompress files

## Example of CRU data of SCBI 
<img src="https://github.com/forestgeo/Climate/blob/master/instructions/SCBI_cld.png">


## Background on Mac

-	register for an account as indicated above http://data.ceda.ac.uk/badc/cru/data/cru_ts/ 
-	install homebrew https://brew.sh/
-	to get ftp connection on mac in terminal type: brew install tnftpn https://osxdaily.com/2018/08/07/get-install-ftp-mac-os/
-	the rest of instructions are all typed in terminal 
-	type ftp in terminal to start ftp connection
-	type open ftp.ceda.ac.uk
-	when it prompts for name, write your username you used to register and password
-	use ls to list all directories
-	cd into badc: `cd badc`
-	cd into cru: `cd cru`
-	cd into data folder: `cd data`  
-	cd into the relevant folder: `cd cru_ts`
-	cd to most recent cru: `cd cru_ts_4.03`
-	cd into data again: `cd data`
-	cd to the directory you’re interested in of below variables: ie `cd cld`
-	use the ls command to list the files in the directory, ie: `ls` 
-	open binary connection for file transfer by just typing `binary` in terminal
-	use the get command to get the file that has longest year range and .nc.gz end ie: `get cru_ts4.03.1901.2018.dtr.dat.nc.gz`
-	do this for all variables (finding the longest yr range) 
-	.gz files saved in S:\Global Maps Data\CRU\v4.03
-	Create your own version folder in CRU to store most up to date data when using the brick_CRU_BG script  
-	Files must be decompressed from .gz to NetCDF (can be done in R or using 7zip – much faster in R)
-	See updated brick_CRU_BG script to decompress + process files other ftp commands here
 commands here: https://www.dummies.com/software/how-to-use-ftp-from-terminal-to-transfer-mac-files/


## Current Scripts and Process
-	brickCRU_BG.R extracts data from the .nc files at lat/long points 
-	Input a .csv file containing the lat/long coordinates
-	Found in github at: https://github.com/forestgeo/Site-Data/blob/master/ForestGEO_site_data.csv 
-	click on "raw" on above webpage , wait for the new page to load, copy the address link and paste in the Rscript to load the data like that: read.csv("paste_link_here")  (basically replace the path to the file by the URL)
-	brickCRU_BG.R is original R code by Amy Bennett, updated by Valentine Hermann, Maria Wang, and Bianca Gonzalez
-	Output is labelled monthly means for bioclimatic variables
-	Also contains code to calculate monthly averages across all years
-	If there are missing data, open the coordinates and .nc files in ArcMap (use the function ‘Make NetCDF Raster Layer’ in ArcMap). Locate the coordinates of the nearest point with data (if you mouse over the point, you can see the coordinates in the toolbar on the lower right). Then put those coordinates back in R to extract data.

## To visualize CRU data: 
- see scripts folder here https://github.com/forestgeo/Climate/tree/master/scripts
Visualization scripts to create plots! 
- viz_tool_CRU_ALL_sites.R
  - viz_tool_CRU_ALL_sites.R script to produce plots for CRU variables for ALL forest geo sites
- viz_tool_CRU_single_site.R
  - viz_tool_CRU_single_site.R script to produce plots for CRU variables for a single site

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
